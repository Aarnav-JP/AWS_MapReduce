# üé¨ Movie Analytics with AWS MapReduce

[![AWS](https://img.shields.io/badge/AWS-EMR-FF9900?logo=amazon-aws&logoColor=white)](https://aws.amazon.com/emr/)
[![Terraform](https://img.shields.io/badge/Terraform-IaC-623CE4?logo=terraform&logoColor=white)](https://www.terraform.io/)
[![Hadoop](https://img.shields.io/badge/Hadoop-MapReduce-66CCFF?logo=apache&logoColor=white)](https://hadoop.apache.org/)
[![Java](https://img.shields.io/badge/Java-Development-007396?logo=java&logoColor=white)](https://www.java.com/)

A production-grade **Big Data analytics pipeline** that processes the 335MB MovieLens dataset using a custom Hadoop MapReduce application on AWS EMR. The entire infrastructure is provisioned automatically using **Infrastructure as Code (Terraform)**.

## üìã Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Technologies](#-technologies)
- [Prerequisites](#-prerequisites)
- [Project Structure](#-project-structure)
- [Setup & Deployment](#-setup--deployment)
- [Usage](#-usage)
- [Analytics Outputs](#-analytics-outputs)
- [Results](#-results)
- [Clean Up](#-clean-up)
- [Demo](#-demo)
- [License](#-license)

## üåü Overview

This project demonstrates a complete Big Data processing pipeline using AWS cloud services. It analyzes the [MovieLens Latest Dataset](https://grouplens.org/datasets/movielens/latest/) (335MB, 33+ million ratings) to deliver actionable movie analytics through distributed computing.

### Core Analytics Tasks

1. **Average Movie Ratings**: Calculate the mean rating and total number of ratings for each movie
2. **Genre-Based Top Movies**: Identify the Top-10 highest-rated movies per genre (minimum 50 ratings threshold)

## ‚ú® Features

- üèóÔ∏è **Infrastructure as Code**: Fully automated EMR cluster deployment using Terraform
- ‚ö° **Multi-Step MapReduce Pipeline**: Two chained MapReduce jobs for complex analytics
- üîí **Secure AWS Configuration**: Dedicated VPC with properly configured security groups
- üì¶ **S3 Integration**: Automated data and code storage management
- üîÑ **End-to-End Automation**: Complete scripts for building, deploying, and executing
- üìä **Large-Scale Processing**: Handles 33M+ ratings and 86K+ movies efficiently
- üéØ **Production-Ready**: Multi-node cluster with proper resource allocation

## üèõÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Developer     ‚îÇ
‚îÇ   (Your PC)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ terraform apply
         ‚îú‚îÄ build.sh
         ‚îú‚îÄ aws s3 cp
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄv‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ             AWS Cloud                       ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
    ‚îÇ  ‚îÇ   S3 Bucket (Data & Code Storage)   ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚Ä¢ movies.csv                        ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚Ä¢ ratings.csv                       ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚Ä¢ movie-analysis.jar                ‚îÇ   ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
    ‚îÇ                 ‚îÇ                            ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄv‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
    ‚îÇ  ‚îÇ       EMR Cluster (Hadoop)          ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ                                      ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚îÇ  Master Node (m5.xlarge)      ‚îÇ  ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ YARN ResourceManager       ‚îÇ  ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ HDFS NameNode              ‚îÇ  ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ                                      ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚îÇ  Worker 1 ‚îÇ   ‚îÇ  Worker 2 ‚îÇ     ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚îÇ(m5.xlarge)‚îÇ   ‚îÇ(m5.xlarge)‚îÇ     ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ                                      ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  MapReduce Job Flow:                ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  Job 1: ratings.csv ‚Üí avg ratings   ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  Job 2: movies.csv + Job1 ‚Üí top10   ‚îÇ   ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
    ‚îÇ                                              ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
    ‚îÇ  ‚îÇ   HDFS Output                        ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚Ä¢ /output1 (avg ratings)            ‚îÇ   ‚îÇ
    ‚îÇ  ‚îÇ  ‚Ä¢ /output2 (genre top-10)           ‚îÇ   ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Workflow

1. **Provision Infrastructure**: Terraform creates EMR cluster, S3 buckets, IAM roles, and security groups
2. **Upload Data & Code**: Dataset and compiled JAR uploaded to S3
3. **Distributed Processing**: MapReduce jobs execute on multi-node cluster
4. **Results Retrieval**: Final analytics available in HDFS

## üõ†Ô∏è Technologies

| Category | Technologies |
|----------|-------------|
| **Cloud Platform** | AWS (EMR, EC2, S3, IAM, VPC) |
| **Infrastructure** | Terraform (HashiCorp Configuration Language) |
| **Big Data Framework** | Apache Hadoop 3.x (EMR 6.15.0) |
| **Processing Paradigm** | MapReduce |
| **Programming Language** | Java 8 |
| **Build Tools** | Bash, JAR packaging |

## ‚öôÔ∏è Prerequisites

Before running this project, ensure you have:

- ‚úÖ **AWS Account** with appropriate permissions (EMR, EC2, S3, IAM)
- ‚úÖ **AWS CLI** configured with credentials (`aws configure`)
- ‚úÖ **Terraform** installed (v1.0+)
- ‚úÖ **Java JDK 8** or higher
- ‚úÖ **Hadoop** (optional, for local development/testing)
- ‚úÖ **SSH Key Pair** created in AWS for EMR access

### Installation Commands

```bash
# Install AWS CLI (macOS)
brew install awscli

# Install Terraform
brew install terraform

# Install Java (if needed)
brew install openjdk@8

# Install Hadoop (optional)
brew install hadoop
```

## üìÅ Project Structure

```
movie-analysis-project/
‚îú‚îÄ‚îÄ data/                           # MovieLens dataset (335MB+)
‚îÇ   ‚îú‚îÄ‚îÄ movies.csv                  # Movie metadata (86K movies)
‚îÇ   ‚îú‚îÄ‚îÄ ratings.csv                 # User ratings (33M+ ratings)
‚îÇ   ‚îú‚îÄ‚îÄ tags.csv                    # User-generated tags
‚îÇ   ‚îú‚îÄ‚îÄ links.csv                   # Links to IMDB/TMDB
‚îÇ   ‚îú‚îÄ‚îÄ genome-scores.csv           # Tag relevance scores
‚îÇ   ‚îî‚îÄ‚îÄ genome-tags.csv             # Tag descriptions
‚îÇ
‚îú‚îÄ‚îÄ MovieRatingMapper.java          # Job 1: Map ratings to movies
‚îú‚îÄ‚îÄ MovieRatingReducer.java         # Job 1: Calculate avg ratings
‚îú‚îÄ‚îÄ GenreTopMoviesMapper.java       # Job 2: Map movies with ratings
‚îú‚îÄ‚îÄ GenreTopMoviesReducer.java      # Job 2: Find top-10 per genre
‚îú‚îÄ‚îÄ MovieAnalysisDriver.java        # Main driver (orchestrates jobs)
‚îÇ
‚îú‚îÄ‚îÄ build.sh                        # Build script (compile & package)
‚îú‚îÄ‚îÄ movie-analysis.jar              # Compiled JAR file
‚îú‚îÄ‚îÄ the2.tf                         # Terraform infrastructure config
‚îú‚îÄ‚îÄ command.txt                     # AWS deployment commands
‚îî‚îÄ‚îÄ README.md                       # This file
```

## üöÄ Setup & Deployment

### Step 1: Configure Terraform Variables

Edit `the2.tf` and update the following variables:

```hcl
variable "student_id" {
  default = "your-unique-id"  # Change this to your unique identifier
}

variable "key_pair_name" {
  default = "your-key-pair"   # Change to your AWS key pair name
}
```

### Step 2: Build the Application

```bash
# Compile Java code and create JAR
chmod +x build.sh
./build.sh
```

This creates `movie-analysis.jar` in the project root.

### Step 3: Provision Infrastructure

```bash
# Initialize Terraform
terraform init

# Review infrastructure plan
terraform plan

# Deploy EMR cluster and resources
terraform apply
# Type 'yes' when prompted
```

**Note**: Cluster provisioning takes ~10-15 minutes.

### Step 4: Upload Data and Code to S3

```bash
# Set your S3 bucket name (from Terraform output)
BUCKET_NAME=$(terraform output -raw s3_bucket_name)

# Upload Java source files
aws s3 cp MovieRatingMapper.java s3://$BUCKET_NAME/src/
aws s3 cp MovieRatingReducer.java s3://$BUCKET_NAME/src/
aws s3 cp GenreTopMoviesMapper.java s3://$BUCKET_NAME/src/
aws s3 cp GenreTopMoviesReducer.java s3://$BUCKET_NAME/src/
aws s3 cp MovieAnalysisDriver.java s3://$BUCKET_NAME/src/

# Upload dataset
aws s3 cp data/ratings.csv s3://$BUCKET_NAME/input/
aws s3 cp data/movies.csv s3://$BUCKET_NAME/input/
```

## üíª Usage

### Step 1: Connect to EMR Master Node

```bash
# Get master node DNS from Terraform
MASTER_DNS=$(terraform output -raw master_public_dns)

# SSH into master node
ssh -i your-key-pair.pem hadoop@$MASTER_DNS
```

### Step 2: Prepare Environment on EMR

```bash
# Verify cluster is ready
yarn node -list

# Download source code from S3
BUCKET_NAME="your-bucket-name"  # Use your bucket
aws s3 cp s3://$BUCKET_NAME/src/ ./ --recursive

# Compile Java code
export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jar
hadoop com.sun.tools.javac.Main *.java

# Package into JAR
jar cf movie-analysis.jar *.class
```

### Step 3: Prepare HDFS

```bash
# Create input directory
hdfs dfs -mkdir -p /input

# Clean up any previous outputs
hdfs dfs -rm -r /output1 2>/dev/null || true
hdfs dfs -rm -r /output2 2>/dev/null || true

# Download and upload data to HDFS
aws s3 cp s3://$BUCKET_NAME/input/ratings.csv ./
aws s3 cp s3://$BUCKET_NAME/input/movies.csv ./

hdfs dfs -put ratings.csv /input/
hdfs dfs -put movies.csv /input/
```

### Step 4: Run MapReduce Jobs

```bash
# Execute the two-stage MapReduce pipeline
hadoop jar movie-analysis.jar MovieAnalysisDriver /input /output1 /output2
```

### Step 5: View Results

```bash
# View average ratings (Job 1 output)
hdfs dfs -cat /output1/part-r-00000 | head -20

# View top-10 movies per genre (Job 2 output)
hdfs dfs -cat /output2/part-r-00000 | head -50
```

## üìä Analytics Outputs

### Job 1: Average Movie Ratings

**Format**: `MovieID\t{Title}\tAvgRating\tNumRatings`

```
1    Toy Story (1995)        3.92    247
2    Jumanji (1995)          3.43    187
356  Forrest Gump (1994)     4.16    329
```

### Job 2: Top-10 Movies Per Genre

**Format**: `Genre\tRank\t{Title}\tAvgRating\tNumRatings`

```
Action    1    The Dark Knight (2008)           4.35    1247
Action    2    Inception (2010)                 4.31    986
...
Drama     1    The Shawshank Redemption (1994)  4.49    1523
Drama     2    The Godfather (1972)             4.42    1167
```

## üéØ Results

The MapReduce pipeline processes:
- **33+ million ratings**
- **86,000+ movies**
- **20+ genres**

And produces:
- Complete average ratings for all rated movies
- Top-10 highest-rated movies for each genre (with ‚â•50 ratings)
- Processing time: ~5-8 minutes on a 3-node cluster

## üßπ Clean Up

### Destroy Infrastructure

```bash
# Terminate EMR cluster and delete all resources
terraform destroy
# Type 'yes' when prompted
```

**Important**: This will delete:
- EMR cluster
- S3 buckets and all data
- IAM roles and policies
- Security groups

## üé• Demo

A video demonstration of the project execution and explanation is available:

**[View Demo Videos](https://drive.google.com/drive/folders/12q7SfpATKqhqUh1wGvl55CYssQtqLEKT?usp=drive_link)**

The demo includes:
- `execution.mov` - Complete deployment and execution walkthrough
- `explanation.mov` - Technical architecture and code explanation

## üìù License

This project is for educational purposes as part of cloud computing coursework.

---

**Dataset Credit**: [GroupLens Research - MovieLens Latest Dataset](https://grouplens.org/datasets/movielens/latest/)

**Author**: BITS Pilani Cloud Computing Assignment  
**Course**: Cloud Computing (SEM3)
